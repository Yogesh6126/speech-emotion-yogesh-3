{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1470ef5",
   "metadata": {},
   "source": [
    "# Speech Emotion Detection (Machine Learning)\n",
    "\n",
    "Author: Yogesh (Yogesh6126)\n",
    "\n",
    "This notebook builds a simple ML pipeline for speech emotion detection using synthetic audio samples. It is designed to run in Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bddc22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies in Colab/local environment (run once)\n",
    "!pip install --quiet -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeddffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create folder for audio samples\n",
    "os.makedirs('audio_samples', exist_ok=True)\n",
    "\n",
    "# Sampling params\n",
    "sr = 16000\n",
    "duration = 1.5  # seconds\n",
    "\n",
    "def make_tone(freq, sr=sr, duration=duration, amplitude=0.5, phase=0.0):\n",
    "    t = np.linspace(0, duration, int(sr*duration), endpoint=False)\n",
    "    return amplitude * np.sin(2*np.pi*freq*t + phase)\n",
    "\n",
    "# Generate synthetic audio for emotions\n",
    "emotions = ['happy','sad','angry','neutral']\n",
    "np.random.seed(42)\n",
    "rows = []\n",
    "for emo in emotions:\n",
    "    for i in range(15):  # 15 samples per emotion\n",
    "        if emo == 'happy':\n",
    "            freq = np.random.uniform(300,600)  # higher pitch\n",
    "            amp = np.random.uniform(0.4,0.8)\n",
    "            y = make_tone(freq, amplitude=amp)\n",
    "            # add light vibrato\n",
    "            y += 0.02 * make_tone(freq*1.01, amplitude=1.0)\n",
    "        elif emo == 'sad':\n",
    "            freq = np.random.uniform(120,220)  # lower pitch\n",
    "            amp = np.random.uniform(0.1,0.4)\n",
    "            y = make_tone(freq, amplitude=amp)\n",
    "        elif emo == 'angry':\n",
    "            # mix of high energy and added noise\n",
    "            freq = np.random.uniform(250,450)\n",
    "            amp = np.random.uniform(0.6,1.0)\n",
    "            y = make_tone(freq, amplitude=amp)\n",
    "            y += 0.15 * np.random.randn(len(y))\n",
    "        else:  # neutral\n",
    "            freq = np.random.uniform(180,300)\n",
    "            amp = np.random.uniform(0.2,0.5)\n",
    "            y = make_tone(freq, amplitude=amp)\n",
    "            y += 0.01 * np.random.randn(len(y))\n",
    "\n",
    "        fname = f'audio_samples/{emo}_{i}.wav'\n",
    "        sf.write(fname, y, sr)\n",
    "        rows.append({'filename': fname, 'emotion': emo})\n",
    "\n",
    "# Create a CSV manifest\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv('metadata.csv', index=False)\n",
    "print('Created', len(df), 'synthetic audio samples and metadata.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404b3250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction using librosa\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "meta = pd.read_csv('metadata.csv')\n",
    "features = []\n",
    "for idx,row in meta.iterrows():\n",
    "    y, sr = librosa.load(row['filename'], sr=None)\n",
    "    # MFCCs (take mean of first 13 coefficients)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfcc_mean = mfcc.mean(axis=1)\n",
    "    # Spectral centroid\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr).mean()\n",
    "    # Zero crossing rate\n",
    "    zcr = librosa.feature.zero_crossing_rate(y).mean()\n",
    "    # RMS energy\n",
    "    rms = librosa.feature.rms(y).mean()\n",
    "    feat = np.concatenate([mfcc_mean, [spec_cent, zcr, rms]])\n",
    "    features.append(feat)\n",
    "\n",
    "feat_names = [f'mfcc_{i+1}' for i in range(13)] + ['spec_centroid','zcr','rms']\n",
    "X = pd.DataFrame(features, columns=feat_names)\n",
    "y = meta['emotion']\n",
    "print('Feature matrix shape:', X.shape)\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1108dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split and model training (RandomForest)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\n",
    "print('Confusion matrix (rows=true, cols=pred):')\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8341447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions.csv\n",
    "pred_df = X_test.copy()\n",
    "pred_df['true'] = y_test.values\n",
    "pred_df['predicted'] = y_pred\n",
    "pred_df.to_csv('predictions.csv', index=False)\n",
    "print('Saved predictions.csv with', len(pred_df), 'rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938ce011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple plot of feature importance\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "importances = clf.feature_importances_\n",
    "inds = np.argsort(importances)[::-1][:10]\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.title('Top 10 Feature importances')\n",
    "plt.bar(range(len(inds)), importances[inds])\n",
    "plt.xticks(range(len(inds)), [X.columns[i] for i in inds], rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a99b3c",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- The notebook generates synthetic audio so you can run everything offline in Colab without external datasets.\n",
    "- Replace `audio_samples` and `metadata.csv` with a real dataset (RAVDESS, CREMA-D) for production-level experiments.\n",
    "- This uses classical ML (RandomForest) for speed and simplicity; you can switch to deep learning easily."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
